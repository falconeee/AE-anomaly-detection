{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13bb3d68",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c817a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
    "from utils.futurai_ppd import drop_transitorio_desligado\n",
    "from utils.futurai_utils import select_training_period\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed\n",
    "\n",
    "# Silenciar logs menos importantes do TensorFlow\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af3d636",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = 'Timestamp'\n",
    "\n",
    "df_dataset = pd.read_csv('data/Depurador 762-28-006 - Cozimento.csv', sep=';', decimal='.', encoding='utf-8-sig')\n",
    "df_dataset.drop(columns=[\"762P0013.OP\", \"762F0040.OP\", \"762F0014.SP\", \"762H0336.PV\", \"762H0342.PV\", \"762N0015.SP\", \"762P0013.SP\", \"762-34-073.CR\", \"762N0015.OP\"], inplace=True, errors='ignore')\n",
    "df_dataset.dropna(inplace=True)\n",
    "df_dataset[timestamp] = pd.to_datetime(df_dataset[timestamp], format='%Y-%m-%d %H:%M:%S')\n",
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60001a54",
   "metadata": {},
   "source": [
    "# Remove periods off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a83b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process = []\n",
    "pp_var_ref_desligado = \"762-28-006.CR\"\n",
    "pp_valor_ref_desligado = 5\n",
    "pp_tempo_ref_desligado = 0\n",
    "pp_pre_corte_transitorio = 0\n",
    "pp_pos_corte_transitorio = 0\n",
    "pre_process.append(  \n",
    "{\n",
    "   \"after_cut\": pp_pos_corte_transitorio,\n",
    "   \"interval_off\": pp_tempo_ref_desligado,\n",
    "   \"limit_off\": pp_valor_ref_desligado,\n",
    "   \"pre_cut\": pp_pre_corte_transitorio,\n",
    "   \"variable_off\": pp_var_ref_desligado\n",
    "  })\n",
    "\n",
    "for pro in pre_process:\n",
    "    df_dataset,_,_ = drop_transitorio_desligado(df_dataset,pro[\"variable_off\"],pro[\"limit_off\"],pro[\"interval_off\"],timestamp,pre_corte=pro[\"pre_cut\"],pos_corte=pro[\"after_cut\"])\n",
    "print(f\"Dataset shape: {df_dataset.shape}\")\n",
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b14288",
   "metadata": {},
   "source": [
    "# Select training periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_training_period = select_training_period(df_dataset, timestamp)\n",
    "fig_training_period.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6ad8cb",
   "metadata": {},
   "source": [
    "# Split train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b38c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_train = pd.to_datetime('2024-02-25 00:00:00')\n",
    "end_date_train = pd.to_datetime('2024-03-12 00:00:00')\n",
    "\n",
    "mask = (df_dataset[timestamp] >= start_date_train) & (df_dataset[timestamp] <= end_date_train)\n",
    "df_train = df_dataset.loc[mask]\n",
    "\n",
    "eixo_timestamp_train = df_train[timestamp]\n",
    "df_train = df_train.drop(columns=[timestamp])\n",
    "print(f\"Training set shape: {df_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ea7768",
   "metadata": {},
   "source": [
    "# Set test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c1e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = df_dataset.copy()\n",
    "eixo_timestamp_teste = df_teste[timestamp]\n",
    "df_teste = df_teste.drop(columns=[timestamp])\n",
    "print(f\"Test set shape: {df_teste.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7482a071",
   "metadata": {},
   "source": [
    "# Create Data Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827c33e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data, window_size, batch_size):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        # Retorna o número de lotes (batches) por época\n",
    "        return int(np.floor(len(self.data) - self.window_size + 1) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Gera um lote (batch) de dados\n",
    "        start_idx = idx * self.batch_size\n",
    "        end_idx = start_idx + self.batch_size\n",
    "\n",
    "        batch_windows = []\n",
    "        for i in range(start_idx, end_idx):\n",
    "            if i + self.window_size <= len(self.data):\n",
    "                batch_windows.append(self.data[i : i + self.window_size])\n",
    "        \n",
    "        batch_windows = np.array(batch_windows)\n",
    "        # Para autoencoders, o input e o target são os mesmos\n",
    "        return batch_windows, batch_windows\n",
    "\n",
    "WINDOW_SIZE = 1440\n",
    "BATCH_SIZE = 64  # Ajuste conforme a memória da sua GPU/CPU\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train)\n",
    "\n",
    "train_data_scaled = scaler.transform(df_train)\n",
    "test_data_scaled = scaler.transform(df_teste)\n",
    "\n",
    "train_generator = WindowGenerator(train_data_scaled, WINDOW_SIZE, BATCH_SIZE)\n",
    "test_generator = WindowGenerator(test_data_scaled, WINDOW_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed4f0e9",
   "metadata": {},
   "source": [
    "# Build autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3049e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_autoencoder(input_shape):\n",
    "    \"\"\"Cria e compila um modelo de Autoencoder LSTM.\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    encoded = LSTM(128, activation='relu', return_sequences=False)(inputs)\n",
    "    encoded = RepeatVector(input_shape[0])(encoded)\n",
    "    decoded = LSTM(128, activation='relu', return_sequences=True)(encoded)\n",
    "    decoded = TimeDistributed(Dense(input_shape[1]))(decoded)\n",
    "    autoencoder = Model(inputs, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mae')\n",
    "    autoencoder.summary()\n",
    "    return autoencoder\n",
    "\n",
    "num_features = train_data_scaled.shape[1]\n",
    "input_shape = (WINDOW_SIZE, num_features) \n",
    "autoencoder = create_lstm_autoencoder(input_shape)\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min')]\n",
    ")\n",
    "\n",
    "predict_train_generator = WindowGenerator(train_data_scaled, WINDOW_SIZE, BATCH_SIZE, shuffle=False)\n",
    "predict_test_generator = WindowGenerator(test_data_scaled, WINDOW_SIZE, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_pred = autoencoder.predict(predict_train_generator)\n",
    "test_pred = autoencoder.predict(predict_test_generator)\n",
    "\n",
    "def get_original_windows(generator):\n",
    "    windows = []\n",
    "    for i in range(len(generator)):\n",
    "        x, _ = generator[i]\n",
    "        windows.append(x)\n",
    "    return np.concatenate(windows)\n",
    "\n",
    "train_originals = get_original_windows(predict_train_generator)\n",
    "test_originals = get_original_windows(predict_test_generator)\n",
    "\n",
    "min_len_train = min(len(train_pred), len(train_originals))\n",
    "min_len_test = min(len(test_pred), len(test_originals))\n",
    "\n",
    "# Calcule o MAE para cada janela\n",
    "train_mae_loss = np.mean(np.abs(train_pred[:min_len_train] - train_originals[:min_len_train]), axis=(1, 2))\n",
    "test_mae_loss = np.mean(np.abs(test_pred[:min_len_test] - test_originals[:min_len_test]), axis=(1, 2))\n",
    "\n",
    "print(f\"\\nForma do array de erro de treino: {train_mae_loss.shape}\")\n",
    "print(f\"Forma do array de erro de teste: {test_mae_loss.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3775388",
   "metadata": {},
   "source": [
    "# Plot and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstruction_error(error_df, threshold):\n",
    "    \"\"\"Plota o erro de reconstrução e o limiar de anomalia.\"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(error_df.index, error_df['error'], label='Erro de Reconstrução')\n",
    "    plt.axhline(y=threshold, color='r', linestyle='--', label='Limiar de Anomalia')\n",
    "    plt.title('Erro de Reconstrução ao Longo do Tempo')\n",
    "    plt.xlabel('Data')\n",
    "    plt.ylabel('Erro (MAE)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
